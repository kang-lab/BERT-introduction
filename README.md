# BERT-introduction

BERT is one of the most common baseline large language model trained using a masked language modeling objective. It was created using the transformer [architecture](https://arxiv.org/abs/1706.03762) and was introduced with [this paper](https://arxiv.org/abs/1810.04805)

